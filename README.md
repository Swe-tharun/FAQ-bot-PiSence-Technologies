Hereâ€™s a **well-structured README** for your FAQ Chatbot project:  

---

## **ğŸ“Œ FAQ Chatbot using DistilBERT**
An AI-powered **FAQ Chatbot** that predicts answers from a dataset of frequently asked questions. The dataset was created by **scraping the PiSence Technologies website** and fine-tuning **DistilBERT** for question answering.

---

## **ğŸš€ Project Overview**
This chatbot uses **Natural Language Processing (NLP)** to find relevant answers for user queries. It first finds the most similar question using **Sentence Transformers** and then extracts the precise answer using **DistilBERT**.

### **ğŸ” How It Works**
1. **Web Scraping** â€“ Extracted FAQs from the **PiSence Technologies website**.
2. **Dataset Preparation** â€“ Cleaned and structured the extracted data.
3. **Fine-Tuning** â€“ Trained **DistilBERT** (`distilbert-base-uncased`) on the dataset.
4. **Embedding Similarity** â€“ Used `paraphrase-MiniLM-L6-v2` for ranking relevant FAQs.
5. **Question Answering** â€“ The chatbot extracts the most relevant answer.

---

## **ğŸ“‘ Technologies Used**
âœ… **Python**  
âœ… **Streamlit** (For UI)  
âœ… **PyTorch** (For fine-tuning)  
âœ… **Transformers** (Hugging Face library)  
âœ… **Sentence Transformers** (For semantic similarity)  
âœ… **Pandas** (For dataset handling)  
âœ… **BeautifulSoup** (For web scraping)  

---

## **ğŸ¯ Model Performance**
- **Accuracy**: 87% on the test dataset  
- **Dataset**: Scraped from **PiSence Technologies**  
- **Fine-Tuned Model**: `distilbert-base-uncased`  

---

## **ğŸ“‚ Installation & Setup**
### **ğŸ”¹ Clone the Repository**
```bash
git clone https://github.com/your-username/faq-chatbot.git
cd faq-chatbot
```

### **ğŸ”¹ Install Dependencies**
```bash
pip install -r requirements.txt
```

### **ğŸ”¹ Download & Setup the Model**
If the model is not found, run:
```bash
chmod +x download_models.sh
./download_models.sh
```

Or, you can manually download:
```bash
huggingface-cli download distilbert-base-uncased-distilled-squad --local-dir models/fqa-distilbert
```

### **ğŸ”¹ Run the Chatbot**
```bash
streamlit run app.py
```

---

## **ğŸ›  Troubleshooting**
### **1ï¸âƒ£ Import Error: `Dilbert is not correctly imported`**
- **Solution**: Restart the local server:
```bash
streamlit run app.py
```

### **2ï¸âƒ£ Model Not Found**
- **Solution**: Run the model download script again:
```bash
./download_models.sh
```

### **3ï¸âƒ£ Streamlit Not Found**
- **Solution**: Install it:
```bash
pip install streamlit
```
## ğŸš€ Common Errors While Training

### 1ï¸âƒ£ What if the model `fqa-distilbert` or `distilbert-base-uncased` is not found?  
âœ… After running `train.py`, a folder named **models/fqa-distilbert** will be **automatically created** with the trained model.  
âš ï¸ If it's missing, ensure the training script has been executed successfully.

### 2ï¸âƒ£ How can I improve the model accuracy?  
ğŸ”¹ **Increase the batch size** (`per_device_train_batch_size=16` or higher, if GPU allows).  
ğŸ”¹ **Increase the number of epochs** (e.g., `num_train_epochs=15` for better learning).  
ğŸ”¹ **Use a larger model** like `bert-base-uncased` instead of `distilbert-base-uncased`.  

---

## **ğŸ“Œ Future Enhancements**
- âœ… Add **voice-based query support** ğŸ¤  
- âœ… Improve **response accuracy** with more training data ğŸ“Š  
- âœ… Deploy as a **web app** using **AWS/GCP** ğŸŒ  

---

## **ğŸ“ Contact**
ğŸ“§ **Email**: tharunsivaraj0325@gmail.com  
ğŸ”— **GitHub**: https://github.com/Swe-tharun

ğŸš€ **Happy Coding!** ğŸ˜Š
